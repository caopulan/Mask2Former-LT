_BASE_: ../maskformer2_R50_bs16_160k.yaml
MODEL:
  BACKBONE:
    NAME: "D2VisionTransformer"
  WEIGHTS: "pretrained_weights/mae_pretrain_vit_base.pkl"
  VIT:
    EMBED_DIM: 768
    DEPTH: 12
    NUM_HEAD: 12
    APE: True
    DROP_PATH_RATE: 0.1
    PYRAMID_DIM: 256
    PRETRAIN_IMG_SIZE: 224
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  MAX_ITER: 160000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WEIGHT_DECAY: 0.05
  OPTIMIZER: "ADAMW"
  LR_SCHEDULER_NAME: "WarmupPolyLR"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: !!python/object/apply:eval ["[int(x * 0.1 * 640) for x in range(5, 21)]"]
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 2560
  MAX_SIZE_TEST: 2560
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (640, 640)
    SINGLE_CATEGORY_MAX_AREA: 1.0
  COLOR_AUG_SSD: True
  SIZE_DIVISIBILITY: 640  # used in dataset mapper
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 10000
  AUG:
    ENABLED: False
    MIN_SIZES: [320, 480, 640, 800, 960, 1120]
    MAX_SIZE: 4480
    FLIP: True
